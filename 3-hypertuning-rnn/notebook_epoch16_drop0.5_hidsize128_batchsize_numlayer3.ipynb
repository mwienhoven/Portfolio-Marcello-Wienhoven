{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.2.5'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import List\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from mltrainer import rnn_models, Trainer\n",
    "from torch import optim\n",
    "\n",
    "from mads_datasets import datatools\n",
    "import mltrainer\n",
    "mltrainer.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-07 19:27:17.894\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at C:\\Users\\mwien\\.cache\\mads_datasets\\gestures\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 2600/2600 [00:00<00:00, 2809.38it/s]\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 651/651 [00:00<00:00, 3180.02it/s]\n"
     ]
    }
   ],
   "source": [
    "from mads_datasets import DatasetFactoryProvider, DatasetType\n",
    "from mltrainer.preprocessors import PaddedPreprocessor\n",
    "preprocessor = PaddedPreprocessor()\n",
    "\n",
    "gesturesdatasetfactory = DatasetFactoryProvider.create_factory(DatasetType.GESTURES)\n",
    "streamers = gesturesdatasetfactory.create_datastreamer(batchsize=4, preprocessor=preprocessor)\n",
    "train = streamers[\"train\"]\n",
    "valid = streamers[\"valid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainstreamer = train.stream()\n",
    "validstreamer = valid.stream()\n",
    "x, y = next(iter(trainstreamer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltrainer import TrainerSettings, ReportTypes\n",
    "from mltrainer.metrics import Accuracy\n",
    "\n",
    "accuracy = Accuracy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "    print(\"using cuda\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"using cpu\")\n",
    "\n",
    "# on my mac, at least for the BaseRNN model, mps does not speed up training\n",
    "# probably because the overhead of copying the data to the GPU is too high\n",
    "# so i override the device to cpu\n",
    "device = \"cpu\"\n",
    "# however, it might speed up training for larger models, with more parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the settings for the trainer and the different types of logging you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "epochs: 16\n",
       "metrics: [Accuracy]\n",
       "logdir: gestures\n",
       "train_steps: 650\n",
       "valid_steps: 162\n",
       "reporttypes: [<ReportTypes.TOML: 'TOML'>, <ReportTypes.TENSORBOARD: 'TENSORBOARD'>, <ReportTypes.MLFLOW: 'MLFLOW'>]\n",
       "optimizer_kwargs: {'lr': 0.001, 'weight_decay': 1e-05}\n",
       "scheduler_kwargs: {'factor': 0.5, 'patience': 5}\n",
       "earlystop_kwargs: {'save': True, 'verbose': True, 'patience': 5, 'delta': 0.0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings = TrainerSettings(\n",
    "    epochs=16, # increase this to about 100 for training\n",
    "    metrics=[accuracy],\n",
    "    logdir=Path(\"gestures\"),\n",
    "    train_steps=len(train),\n",
    "    valid_steps=len(valid),\n",
    "    reporttypes=[ReportTypes.TOML, ReportTypes.TENSORBOARD, ReportTypes.MLFLOW],\n",
    "    scheduler_kwargs={\"factor\": 0.5, \"patience\": 5},\n",
    "    earlystop_kwargs = {\n",
    "        \"save\": True, # save every best model, and restore the best one\n",
    "        \"verbose\": True,\n",
    "        \"patience\": 5, # number of epochs with no improvement after which training will be stopped\n",
    "        \"delta\": 0.0, # minimum change to be considered an improvement\n",
    "    }\n",
    ")\n",
    "settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    input_size: int\n",
    "    hidden_size: int\n",
    "    num_layers: int\n",
    "    output_size: int\n",
    "    dropout: float = 0.0\n",
    "\n",
    "class GRUmodel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.rnn = nn.GRU(\n",
    "            input_size=config.input_size,\n",
    "            hidden_size=config.hidden_size,\n",
    "            dropout=config.dropout,\n",
    "            batch_first=True,\n",
    "            num_layers=config.num_layers,\n",
    "        )\n",
    "        self.linear = nn.Linear(config.hidden_size, config.output_size)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x, _ = self.rnn(x)\n",
    "        last_step = x[:, -1, :]\n",
    "        yhat = self.linear(last_step)\n",
    "        return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/07 19:27:20 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2025/10/07 19:27:20 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-07 19:27:20.908\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to gestures\\20251007-192720\u001b[0m\n",
      "\u001b[32m2025-10-07 19:27:22.091\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 650/650 [00:19<00:00, 32.62it/s]\n",
      "\u001b[32m2025-10-07 19:27:43.375\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 1.8197 test 1.1061 metric ['0.6034']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:27:43.375\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (1.1061 --> 1.1061).Saving gestures\\20251007-192720\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 650/650 [00:19<00:00, 32.72it/s]\n",
      "\u001b[32m2025-10-07 19:28:04.285\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.7143 test 0.3695 metric ['0.8873']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:28:04.287\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (1.1061 --> 0.3695).Saving gestures\\20251007-192720\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 650/650 [00:23<00:00, 27.19it/s]\n",
      "\u001b[32m2025-10-07 19:28:29.475\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.2611 test 0.1617 metric ['0.9506']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:28:29.476\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.3695 --> 0.1617).Saving gestures\\20251007-192720\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 650/650 [00:23<00:00, 28.14it/s]\n",
      "\u001b[32m2025-10-07 19:28:53.794\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.1029 test 0.0758 metric ['0.9799']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:28:53.795\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.1617 --> 0.0758).Saving gestures\\20251007-192720\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 650/650 [00:23<00:00, 27.16it/s]\n",
      "\u001b[32m2025-10-07 19:29:18.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.0784 test 0.0886 metric ['0.9769']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:29:18.977\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0758, current loss 0.0886.Counter 1/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 650/650 [00:26<00:00, 24.78it/s]\n",
      "\u001b[32m2025-10-07 19:29:46.548\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 5 train 0.0766 test 0.0947 metric ['0.9784']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:29:46.549\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0758, current loss 0.0947.Counter 2/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 650/650 [00:25<00:00, 25.02it/s]\n",
      "\u001b[32m2025-10-07 19:30:13.812\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 6 train 0.0625 test 0.0556 metric ['0.9877']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:30:13.813\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.0758 --> 0.0556).Saving gestures\\20251007-192720\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 650/650 [00:25<00:00, 25.15it/s]\n",
      "\u001b[32m2025-10-07 19:30:41.193\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 7 train 0.0371 test 0.0531 metric ['0.9907']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:30:41.196\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.0556 --> 0.0531).Saving gestures\\20251007-192720\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 650/650 [00:26<00:00, 24.98it/s]\n",
      "\u001b[32m2025-10-07 19:31:08.534\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 8 train 0.0526 test 0.1655 metric ['0.9583']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:31:08.535\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0531, current loss 0.1655.Counter 1/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 650/650 [00:24<00:00, 26.53it/s]\n",
      "\u001b[32m2025-10-07 19:31:34.321\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 9 train 0.0450 test 0.0302 metric ['0.9938']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:31:34.322\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.0531 --> 0.0302).Saving gestures\\20251007-192720\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 650/650 [00:25<00:00, 25.93it/s]\n",
      "\u001b[32m2025-10-07 19:32:00.777\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 10 train 0.0190 test 0.0413 metric ['0.9907']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:32:00.778\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0302, current loss 0.0413.Counter 1/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 650/650 [00:24<00:00, 26.99it/s]\n",
      "\u001b[32m2025-10-07 19:32:26.490\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 11 train 0.0202 test 0.0403 metric ['0.9938']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:32:26.491\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0302, current loss 0.0403.Counter 2/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 650/650 [00:26<00:00, 24.41it/s]\n",
      "\u001b[32m2025-10-07 19:32:54.371\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 12 train 0.0427 test 0.0552 metric ['0.9892']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:32:54.371\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0302, current loss 0.0552.Counter 3/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 650/650 [00:21<00:00, 29.71it/s]\n",
      "\u001b[32m2025-10-07 19:33:17.294\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 13 train 0.0521 test 0.0957 metric ['0.9799']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:33:17.295\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0302, current loss 0.0957.Counter 4/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 650/650 [00:21<00:00, 30.83it/s]\n",
      "\u001b[32m2025-10-07 19:33:39.431\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 14 train 0.0315 test 0.0582 metric ['0.9892']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:33:39.432\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0302, current loss 0.0582.Counter 5/5.\u001b[0m\n",
      "\u001b[32m2025-10-07 19:33:39.432\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mloop\u001b[0m:\u001b[36m103\u001b[0m - \u001b[1mInterrupting loop due to early stopping patience.\u001b[0m\n",
      "\u001b[32m2025-10-07 19:33:39.432\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mget_best\u001b[0m:\u001b[36m277\u001b[0m - \u001b[1mretrieving best model from gestures\\20251007-192720\\checkpoint.pt\u001b[0m\n",
      " 88%|\u001b[38;2;30;71;6m████████▊ \u001b[0m| 14/16 [06:17<00:53, 26.93s/it]\n",
      "\u001b[32m2025-10-07 19:33:39.538\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to gestures\\20251007-193339\u001b[0m\n",
      "\u001b[32m2025-10-07 19:33:39.541\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 650/650 [00:23<00:00, 27.79it/s]\n",
      "\u001b[32m2025-10-07 19:34:04.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 1.8866 test 1.0541 metric ['0.6373']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:34:04.143\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (1.0541 --> 1.0541).Saving gestures\\20251007-193339\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 650/650 [00:20<00:00, 32.50it/s]\n",
      "\u001b[32m2025-10-07 19:34:25.329\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.6042 test 0.4478 metric ['0.8765']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:34:25.331\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (1.0541 --> 0.4478).Saving gestures\\20251007-193339\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 650/650 [00:22<00:00, 28.51it/s]\n",
      "\u001b[32m2025-10-07 19:34:49.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.2035 test 0.1446 metric ['0.9614']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:34:49.873\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.4478 --> 0.1446).Saving gestures\\20251007-193339\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 650/650 [00:19<00:00, 32.71it/s]\n",
      "\u001b[32m2025-10-07 19:35:10.858\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.1027 test 0.0968 metric ['0.9738']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:35:10.859\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.1446 --> 0.0968).Saving gestures\\20251007-193339\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 650/650 [00:21<00:00, 29.91it/s]\n",
      "\u001b[32m2025-10-07 19:35:33.629\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.0843 test 0.3094 metric ['0.9213']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:35:33.630\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0968, current loss 0.3094.Counter 1/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 650/650 [00:20<00:00, 31.54it/s]\n",
      "\u001b[32m2025-10-07 19:35:55.388\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 5 train 0.0797 test 0.0433 metric ['0.9892']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:35:55.389\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.0968 --> 0.0433).Saving gestures\\20251007-193339\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 650/650 [00:19<00:00, 33.98it/s]\n",
      "\u001b[32m2025-10-07 19:36:15.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 6 train 0.0673 test 0.0479 metric ['0.9907']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:36:15.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0433, current loss 0.0479.Counter 1/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 650/650 [00:21<00:00, 30.29it/s]\n",
      "\u001b[32m2025-10-07 19:36:38.268\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 7 train 0.0189 test 0.0338 metric ['0.9923']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:36:38.269\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.0433 --> 0.0338).Saving gestures\\20251007-193339\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 650/650 [00:20<00:00, 32.36it/s]\n",
      "\u001b[32m2025-10-07 19:36:59.315\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 8 train 0.0595 test 0.1945 metric ['0.9599']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:36:59.315\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0338, current loss 0.1945.Counter 1/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 650/650 [00:21<00:00, 30.19it/s]\n",
      "\u001b[32m2025-10-07 19:37:21.687\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 9 train 0.0639 test 0.0521 metric ['0.9861']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:37:21.688\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0338, current loss 0.0521.Counter 2/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 650/650 [00:19<00:00, 32.95it/s]\n",
      "\u001b[32m2025-10-07 19:37:42.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 10 train 0.0302 test 0.1168 metric ['0.9691']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:37:42.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0338, current loss 0.1168.Counter 3/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 650/650 [00:20<00:00, 31.72it/s]\n",
      "\u001b[32m2025-10-07 19:38:03.786\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 11 train 0.0152 test 0.0467 metric ['0.9923']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:38:03.787\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0338, current loss 0.0467.Counter 4/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 650/650 [00:19<00:00, 33.83it/s]\n",
      "\u001b[32m2025-10-07 19:38:23.846\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 12 train 0.0358 test 0.0445 metric ['0.9923']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:38:23.846\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0338, current loss 0.0445.Counter 5/5.\u001b[0m\n",
      "\u001b[32m2025-10-07 19:38:23.847\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mloop\u001b[0m:\u001b[36m103\u001b[0m - \u001b[1mInterrupting loop due to early stopping patience.\u001b[0m\n",
      "\u001b[32m2025-10-07 19:38:23.847\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mget_best\u001b[0m:\u001b[36m277\u001b[0m - \u001b[1mretrieving best model from gestures\\20251007-193339\\checkpoint.pt\u001b[0m\n",
      " 75%|\u001b[38;2;30;71;6m███████▌  \u001b[0m| 12/16 [04:44<01:34, 23.69s/it]\n",
      "\u001b[32m2025-10-07 19:38:23.917\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to gestures\\20251007-193823\u001b[0m\n",
      "\u001b[32m2025-10-07 19:38:23.918\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 650/650 [00:20<00:00, 31.36it/s]\n",
      "\u001b[32m2025-10-07 19:38:45.773\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 1.8230 test 1.1456 metric ['0.6003']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:38:45.774\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (1.1456 --> 1.1456).Saving gestures\\20251007-193823\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 650/650 [00:21<00:00, 30.25it/s]\n",
      "\u001b[32m2025-10-07 19:39:08.623\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.6235 test 0.3103 metric ['0.9028']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:39:08.625\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (1.1456 --> 0.3103).Saving gestures\\20251007-193823\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 650/650 [00:20<00:00, 32.12it/s]\n",
      "\u001b[32m2025-10-07 19:39:29.879\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.1972 test 0.1300 metric ['0.9691']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:39:29.879\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.3103 --> 0.1300).Saving gestures\\20251007-193823\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 650/650 [00:21<00:00, 30.89it/s]\n",
      "\u001b[32m2025-10-07 19:39:52.046\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.1248 test 0.0938 metric ['0.9753']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:39:52.047\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.1300 --> 0.0938).Saving gestures\\20251007-193823\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 650/650 [00:28<00:00, 22.61it/s]\n",
      "\u001b[32m2025-10-07 19:40:22.288\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.0976 test 0.0608 metric ['0.9877']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:40:22.290\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.0938 --> 0.0608).Saving gestures\\20251007-193823\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 650/650 [00:25<00:00, 25.08it/s]\n",
      "\u001b[32m2025-10-07 19:40:49.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 5 train 0.0704 test 0.1502 metric ['0.9676']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:40:49.829\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0608, current loss 0.1502.Counter 1/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 650/650 [00:26<00:00, 24.74it/s]\n",
      "\u001b[32m2025-10-07 19:41:17.651\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 6 train 0.0375 test 0.0388 metric ['0.9923']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:41:17.652\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.0608 --> 0.0388).Saving gestures\\20251007-193823\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 650/650 [00:26<00:00, 24.24it/s]\n",
      "\u001b[32m2025-10-07 19:41:45.642\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 7 train 0.0350 test 0.0339 metric ['0.9954']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:41:45.643\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.0388 --> 0.0339).Saving gestures\\20251007-193823\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 650/650 [00:28<00:00, 22.51it/s]\n",
      "\u001b[32m2025-10-07 19:42:15.792\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 8 train 0.0672 test 0.0899 metric ['0.9784']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:42:15.793\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0339, current loss 0.0899.Counter 1/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 650/650 [00:27<00:00, 24.03it/s]\n",
      "\u001b[32m2025-10-07 19:42:44.042\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 9 train 0.0360 test 0.0774 metric ['0.9877']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:42:44.043\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0339, current loss 0.0774.Counter 2/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 650/650 [00:30<00:00, 21.19it/s]\n",
      "\u001b[32m2025-10-07 19:43:16.489\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 10 train 0.0505 test 0.0672 metric ['0.9799']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:43:16.489\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0339, current loss 0.0672.Counter 3/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 650/650 [00:28<00:00, 22.77it/s]\n",
      "\u001b[32m2025-10-07 19:43:46.251\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 11 train 0.0327 test 0.0552 metric ['0.9861']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:43:46.252\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0339, current loss 0.0552.Counter 4/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 650/650 [00:28<00:00, 23.19it/s]\n",
      "\u001b[32m2025-10-07 19:44:15.865\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 12 train 0.0301 test 0.0506 metric ['0.9846']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:44:15.866\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0339, current loss 0.0506.Counter 5/5.\u001b[0m\n",
      "\u001b[32m2025-10-07 19:44:15.866\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mloop\u001b[0m:\u001b[36m103\u001b[0m - \u001b[1mInterrupting loop due to early stopping patience.\u001b[0m\n",
      "\u001b[32m2025-10-07 19:44:15.867\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mget_best\u001b[0m:\u001b[36m277\u001b[0m - \u001b[1mretrieving best model from gestures\\20251007-193823\\checkpoint.pt\u001b[0m\n",
      " 75%|\u001b[38;2;30;71;6m███████▌  \u001b[0m| 12/16 [05:51<01:57, 29.33s/it]\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from datetime import datetime\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"gestures\")\n",
    "modeldir = Path(\"gestures\").resolve()\n",
    "if not modeldir.exists():\n",
    "    modeldir.mkdir(parents=True)\n",
    "    \n",
    "n_repeats = 3\n",
    "\n",
    "for repeat in range(n_repeats):\n",
    "    print(f\"Repeat {repeat+1}/{n_repeats}\")\n",
    "    \n",
    "    with mlflow.start_run():\n",
    "        # Set MLflow tags to record metadata about the model and developer\n",
    "        mlflow.set_tag(\"model\", f\"{repeat}_GRU_16epochs_0.5drop_128hidsize_4batch_3numlayer\")\n",
    "        mlflow.set_tag(\"dev\", \"Marcello\")\n",
    "        # Log hyperparameters to MLflow\n",
    "\n",
    "        mlflow.log_param(\"epochs\", settings.epochs)\n",
    "\n",
    "        mlflow.log_param(\"learning_rate\", settings.optimizer_kwargs.get(\"lr\", None))\n",
    "        \n",
    "        config = ModelConfig(\n",
    "            input_size=3,\n",
    "            hidden_size=128,\n",
    "            num_layers=3,\n",
    "            output_size=20,\n",
    "            dropout=0.5,\n",
    "        )\n",
    "\n",
    "        model = GRUmodel(\n",
    "            config=config,\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            settings=settings,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optim.Adam,\n",
    "            traindataloader=trainstreamer,\n",
    "            validdataloader=validstreamer,\n",
    "            scheduler=optim.lr_scheduler.ReduceLROnPlateau,\n",
    "            device=device,\n",
    "        )\n",
    "        trainer.loop()\n",
    "\n",
    "        if not settings.earlystop_kwargs[\"save\"]:\n",
    "            tag = datetime.now().strftime(\"%Y%m%d-%H%M-\")\n",
    "            modelpath = modeldir / (tag + \"model.pt\")\n",
    "            torch.save(model, modelpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open MLFlow\n",
    "\"\"\"\n",
    "```bash\n",
    "mlflow server \\\n",
    "    --backend-store-uri sqlite:///mlflow.db \\\n",
    "    --host 127.0.0.1 \\ \n",
    "    --port 5000 \\\n",
    "        \n",
    "mlflow server --backend-store-uri sqlite:///3-hypertuning-rnn/mlflow.db --host 127.0.0.1 --port 5000\n",
    "```\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "portfolio-example",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
