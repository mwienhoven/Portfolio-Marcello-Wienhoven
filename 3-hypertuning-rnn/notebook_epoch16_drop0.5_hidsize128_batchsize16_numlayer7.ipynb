{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.2.5'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import List\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from mltrainer import rnn_models, Trainer\n",
    "from torch import optim\n",
    "\n",
    "from mads_datasets import datatools\n",
    "import mltrainer\n",
    "mltrainer.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-07 19:49:53.600\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at C:\\Users\\mwien\\.cache\\mads_datasets\\gestures\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 2600/2600 [00:00<00:00, 3382.23it/s]\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 651/651 [00:00<00:00, 3496.19it/s]\n"
     ]
    }
   ],
   "source": [
    "from mads_datasets import DatasetFactoryProvider, DatasetType\n",
    "from mltrainer.preprocessors import PaddedPreprocessor\n",
    "preprocessor = PaddedPreprocessor()\n",
    "\n",
    "gesturesdatasetfactory = DatasetFactoryProvider.create_factory(DatasetType.GESTURES)\n",
    "streamers = gesturesdatasetfactory.create_datastreamer(batchsize=16, preprocessor=preprocessor)\n",
    "train = streamers[\"train\"]\n",
    "valid = streamers[\"valid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainstreamer = train.stream()\n",
    "validstreamer = valid.stream()\n",
    "x, y = next(iter(trainstreamer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltrainer import TrainerSettings, ReportTypes\n",
    "from mltrainer.metrics import Accuracy\n",
    "\n",
    "accuracy = Accuracy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "    print(\"using cuda\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"using cpu\")\n",
    "\n",
    "# on my mac, at least for the BaseRNN model, mps does not speed up training\n",
    "# probably because the overhead of copying the data to the GPU is too high\n",
    "# so i override the device to cpu\n",
    "device = \"cpu\"\n",
    "# however, it might speed up training for larger models, with more parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the settings for the trainer and the different types of logging you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "epochs: 16\n",
       "metrics: [Accuracy]\n",
       "logdir: gestures\n",
       "train_steps: 162\n",
       "valid_steps: 40\n",
       "reporttypes: [<ReportTypes.TOML: 'TOML'>, <ReportTypes.TENSORBOARD: 'TENSORBOARD'>, <ReportTypes.MLFLOW: 'MLFLOW'>]\n",
       "optimizer_kwargs: {'lr': 0.001, 'weight_decay': 1e-05}\n",
       "scheduler_kwargs: {'factor': 0.5, 'patience': 5}\n",
       "earlystop_kwargs: {'save': True, 'verbose': True, 'patience': 5, 'delta': 0.0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings = TrainerSettings(\n",
    "    epochs=16, # increase this to about 100 for training\n",
    "    metrics=[accuracy],\n",
    "    logdir=Path(\"gestures\"),\n",
    "    train_steps=len(train),\n",
    "    valid_steps=len(valid),\n",
    "    reporttypes=[ReportTypes.TOML, ReportTypes.TENSORBOARD, ReportTypes.MLFLOW],\n",
    "    scheduler_kwargs={\"factor\": 0.5, \"patience\": 5},\n",
    "    earlystop_kwargs = {\n",
    "        \"save\": True, # save every best model, and restore the best one\n",
    "        \"verbose\": True,\n",
    "        \"patience\": 5, # number of epochs with no improvement after which training will be stopped\n",
    "        \"delta\": 0.0, # minimum change to be considered an improvement\n",
    "    }\n",
    ")\n",
    "settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    input_size: int\n",
    "    hidden_size: int\n",
    "    num_layers: int\n",
    "    output_size: int\n",
    "    dropout: float = 0.0\n",
    "\n",
    "class GRUmodel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.rnn = nn.GRU(\n",
    "            input_size=config.input_size,\n",
    "            hidden_size=config.hidden_size,\n",
    "            dropout=config.dropout,\n",
    "            batch_first=True,\n",
    "            num_layers=config.num_layers,\n",
    "        )\n",
    "        self.linear = nn.Linear(config.hidden_size, config.output_size)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x, _ = self.rnn(x)\n",
    "        last_step = x[:, -1, :]\n",
    "        yhat = self.linear(last_step)\n",
    "        return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/07 19:49:55 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2025/10/07 19:49:55 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-07 19:49:55.919\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to gestures\\20251007-194955\u001b[0m\n",
      "\u001b[32m2025-10-07 19:49:57.067\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 162/162 [00:12<00:00, 12.69it/s]\n",
      "\u001b[32m2025-10-07 19:50:10.666\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 2.4452 test 1.9168 metric ['0.2906']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:50:10.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (1.9168 --> 1.9168).Saving gestures\\20251007-194955\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 162/162 [00:13<00:00, 12.09it/s]\n",
      "\u001b[32m2025-10-07 19:50:24.846\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 1.6203 test 1.2620 metric ['0.4609']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:50:24.847\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (1.9168 --> 1.2620).Saving gestures\\20251007-194955\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 162/162 [00:13<00:00, 12.17it/s]\n",
      "\u001b[32m2025-10-07 19:50:38.903\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 1.2666 test 1.0896 metric ['0.5094']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:50:38.904\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (1.2620 --> 1.0896).Saving gestures\\20251007-194955\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 162/162 [00:14<00:00, 10.85it/s]\n",
      "\u001b[32m2025-10-07 19:50:54.834\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.9953 test 0.6820 metric ['0.7406']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:50:54.835\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (1.0896 --> 0.6820).Saving gestures\\20251007-194955\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 162/162 [00:20<00:00,  7.86it/s]\n",
      "\u001b[32m2025-10-07 19:51:16.649\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.7956 test 0.5835 metric ['0.7719']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:51:16.650\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.6820 --> 0.5835).Saving gestures\\20251007-194955\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 162/162 [00:15<00:00, 10.26it/s]\n",
      "\u001b[32m2025-10-07 19:51:33.323\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 5 train 0.6864 test 0.5028 metric ['0.8250']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:51:33.324\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.5835 --> 0.5028).Saving gestures\\20251007-194955\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 162/162 [00:16<00:00,  9.93it/s]\n",
      "\u001b[32m2025-10-07 19:51:50.564\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 6 train 0.5300 test 1.0183 metric ['0.7266']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:51:50.564\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.5028, current loss 1.0183.Counter 1/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 162/162 [00:16<00:00,  9.76it/s]\n",
      "\u001b[32m2025-10-07 19:52:08.032\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 7 train 0.4885 test 0.2767 metric ['0.9047']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:52:08.034\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.5028 --> 0.2767).Saving gestures\\20251007-194955\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 162/162 [00:15<00:00, 10.38it/s]\n",
      "\u001b[32m2025-10-07 19:52:24.602\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 8 train 0.3263 test 0.3236 metric ['0.8797']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:52:24.604\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.2767, current loss 0.3236.Counter 1/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 162/162 [00:14<00:00, 11.50it/s]\n",
      "\u001b[32m2025-10-07 19:52:39.412\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 9 train 0.3026 test 0.1904 metric ['0.9281']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:52:39.412\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.2767 --> 0.1904).Saving gestures\\20251007-194955\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 162/162 [00:13<00:00, 11.68it/s]\n",
      "\u001b[32m2025-10-07 19:52:54.029\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 10 train 0.2747 test 0.2091 metric ['0.9297']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:52:54.030\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.1904, current loss 0.2091.Counter 1/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 162/162 [00:17<00:00,  9.22it/s]\n",
      "\u001b[32m2025-10-07 19:53:12.398\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 11 train 0.2394 test 0.2760 metric ['0.9078']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:53:12.399\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.1904, current loss 0.2760.Counter 2/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 162/162 [00:16<00:00, 10.02it/s]\n",
      "\u001b[32m2025-10-07 19:53:29.569\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 12 train 0.2657 test 0.1914 metric ['0.9234']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:53:29.570\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.1904, current loss 0.1914.Counter 3/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 162/162 [00:17<00:00,  9.45it/s]\n",
      "\u001b[32m2025-10-07 19:53:47.530\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 13 train 0.2126 test 0.2279 metric ['0.9313']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:53:47.530\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.1904, current loss 0.2279.Counter 4/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 162/162 [00:15<00:00, 10.64it/s]\n",
      "\u001b[32m2025-10-07 19:54:03.653\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 14 train 0.1949 test 0.1309 metric ['0.9609']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:54:03.654\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.1904 --> 0.1309).Saving gestures\\20251007-194955\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 162/162 [00:14<00:00, 11.37it/s]\n",
      "\u001b[32m2025-10-07 19:54:18.799\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 15 train 0.1938 test 0.1809 metric ['0.9469']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:54:18.800\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.1309, current loss 0.1809.Counter 1/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 16/16 [04:21<00:00, 16.35s/it]\n",
      "\u001b[32m2025-10-07 19:54:18.839\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to gestures\\20251007-195418\u001b[0m\n",
      "\u001b[32m2025-10-07 19:54:18.840\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 162/162 [00:17<00:00,  9.12it/s]\n",
      "\u001b[32m2025-10-07 19:54:37.522\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 2.4688 test 2.1178 metric ['0.1891']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:54:37.525\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (2.1178 --> 2.1178).Saving gestures\\20251007-195418\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 162/162 [00:15<00:00, 10.80it/s]\n",
      "\u001b[32m2025-10-07 19:54:53.370\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 1.7909 test 1.5110 metric ['0.3141']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:54:53.371\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (2.1178 --> 1.5110).Saving gestures\\20251007-195418\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 162/162 [00:15<00:00, 10.55it/s]\n",
      "\u001b[32m2025-10-07 19:55:09.736\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 1.5306 test 1.3865 metric ['0.3797']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:55:09.737\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (1.5110 --> 1.3865).Saving gestures\\20251007-195418\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 162/162 [00:16<00:00, 10.05it/s]\n",
      "\u001b[32m2025-10-07 19:55:26.987\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 1.3226 test 1.1663 metric ['0.4469']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:55:26.988\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (1.3865 --> 1.1663).Saving gestures\\20251007-195418\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 162/162 [00:14<00:00, 10.84it/s]\n",
      "\u001b[32m2025-10-07 19:55:42.651\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 1.0707 test 0.8710 metric ['0.6078']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:55:42.652\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (1.1663 --> 0.8710).Saving gestures\\20251007-195418\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 162/162 [00:16<00:00, 10.09it/s]\n",
      "\u001b[32m2025-10-07 19:55:59.583\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 5 train 0.8116 test 0.7005 metric ['0.7328']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:55:59.583\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.8710 --> 0.7005).Saving gestures\\20251007-195418\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 162/162 [00:14<00:00, 11.31it/s]\n",
      "\u001b[32m2025-10-07 19:56:14.729\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 6 train 0.6496 test 0.5405 metric ['0.7453']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:56:14.729\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.7005 --> 0.5405).Saving gestures\\20251007-195418\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 162/162 [00:14<00:00, 10.81it/s]\n",
      "\u001b[32m2025-10-07 19:56:30.530\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 7 train 0.6378 test 0.4539 metric ['0.8313']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:56:30.531\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.5405 --> 0.4539).Saving gestures\\20251007-195418\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 162/162 [00:17<00:00,  9.50it/s]\n",
      "\u001b[32m2025-10-07 19:56:48.289\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 8 train 0.4324 test 0.3767 metric ['0.8734']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:56:48.290\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.4539 --> 0.3767).Saving gestures\\20251007-195418\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 162/162 [00:14<00:00, 11.30it/s]\n",
      "\u001b[32m2025-10-07 19:57:03.748\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 9 train 0.3425 test 0.2475 metric ['0.9406']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:57:03.748\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.3767 --> 0.2475).Saving gestures\\20251007-195418\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 162/162 [00:18<00:00,  8.64it/s]\n",
      "\u001b[32m2025-10-07 19:57:23.203\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 10 train 0.2847 test 0.1898 metric ['0.9359']\u001b[0m\n",
      "\u001b[32m2025-10-07 19:57:23.204\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.2475 --> 0.1898).Saving gestures\\20251007-195418\\checkpoint.pt ...\u001b[0m\n",
      " 69%|\u001b[38;2;30;71;6m██████▉   \u001b[0m| 11/16 [03:04<01:26, 17.22s/it]"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from datetime import datetime\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"gestures\")\n",
    "modeldir = Path(\"gestures\").resolve()\n",
    "if not modeldir.exists():\n",
    "    modeldir.mkdir(parents=True)\n",
    "    \n",
    "n_repeats = 3\n",
    "\n",
    "for repeat in range(n_repeats):\n",
    "    print(f\"Repeat {repeat+1}/{n_repeats}\")\n",
    "    \n",
    "    with mlflow.start_run():\n",
    "        # Set MLflow tags to record metadata about the model and developer\n",
    "        mlflow.set_tag(\"model\", f\"{repeat}_GRU_16epochs_0.5drop_128hidsize_16batch_7numlayer\")\n",
    "        mlflow.set_tag(\"dev\", \"Marcello\")\n",
    "        # Log hyperparameters to MLflow\n",
    "\n",
    "        mlflow.log_param(\"epochs\", settings.epochs)\n",
    "\n",
    "        mlflow.log_param(\"learning_rate\", settings.optimizer_kwargs.get(\"lr\", None))\n",
    "        \n",
    "        config = ModelConfig(\n",
    "            input_size=3,\n",
    "            hidden_size=128,\n",
    "            num_layers=7,\n",
    "            output_size=20,\n",
    "            dropout=0.5,\n",
    "        )\n",
    "\n",
    "        model = GRUmodel(\n",
    "            config=config,\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            settings=settings,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optim.Adam,\n",
    "            traindataloader=trainstreamer,\n",
    "            validdataloader=validstreamer,\n",
    "            scheduler=optim.lr_scheduler.ReduceLROnPlateau,\n",
    "            device=device,\n",
    "        )\n",
    "        trainer.loop()\n",
    "\n",
    "        if not settings.earlystop_kwargs[\"save\"]:\n",
    "            tag = datetime.now().strftime(\"%Y%m%d-%H%M-\")\n",
    "            modelpath = modeldir / (tag + \"model.pt\")\n",
    "            torch.save(model, modelpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open MLFlow\n",
    "\"\"\"\n",
    "```bash\n",
    "mlflow server \\\n",
    "    --backend-store-uri sqlite:///mlflow.db \\\n",
    "    --host 127.0.0.1 \\ \n",
    "    --port 5000 \\\n",
    "        \n",
    "mlflow server --backend-store-uri sqlite:///3-hypertuning-rnn/mlflow.db --host 127.0.0.1 --port 5000\n",
    "```\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "portfolio-example",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
