{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.2.5'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import List\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from mltrainer import rnn_models, Trainer\n",
    "from torch import optim\n",
    "\n",
    "from mads_datasets import datatools\n",
    "import mltrainer\n",
    "mltrainer.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-04 22:48:15.934\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at C:\\Users\\mwien\\.cache\\mads_datasets\\gestures\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 2600/2600 [00:00<00:00, 3109.60it/s]\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 651/651 [00:00<00:00, 3248.32it/s]\n"
     ]
    }
   ],
   "source": [
    "from mads_datasets import DatasetFactoryProvider, DatasetType\n",
    "from mltrainer.preprocessors import PaddedPreprocessor\n",
    "preprocessor = PaddedPreprocessor()\n",
    "\n",
    "gesturesdatasetfactory = DatasetFactoryProvider.create_factory(DatasetType.GESTURES)\n",
    "streamers = gesturesdatasetfactory.create_datastreamer(batchsize=32, preprocessor=preprocessor)\n",
    "train = streamers[\"train\"]\n",
    "valid = streamers[\"valid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainstreamer = train.stream()\n",
    "validstreamer = valid.stream()\n",
    "x, y = next(iter(trainstreamer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltrainer import TrainerSettings, ReportTypes\n",
    "from mltrainer.metrics import Accuracy\n",
    "\n",
    "accuracy = Accuracy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "    print(\"using cuda\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"using cpu\")\n",
    "\n",
    "# on my mac, at least for the BaseRNN model, mps does not speed up training\n",
    "# probably because the overhead of copying the data to the GPU is too high\n",
    "# so i override the device to cpu\n",
    "device = \"cpu\"\n",
    "# however, it might speed up training for larger models, with more parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the settings for the trainer and the different types of logging you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "epochs: 16\n",
       "metrics: [Accuracy]\n",
       "logdir: gestures\n",
       "train_steps: 81\n",
       "valid_steps: 20\n",
       "reporttypes: [<ReportTypes.TOML: 'TOML'>, <ReportTypes.TENSORBOARD: 'TENSORBOARD'>, <ReportTypes.MLFLOW: 'MLFLOW'>]\n",
       "optimizer_kwargs: {'lr': 0.001, 'weight_decay': 1e-05}\n",
       "scheduler_kwargs: {'factor': 0.5, 'patience': 5}\n",
       "earlystop_kwargs: {'save': True, 'verbose': True, 'patience': 5, 'delta': 0.0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings = TrainerSettings(\n",
    "    epochs=16, # increase this to about 100 for training\n",
    "    metrics=[accuracy],\n",
    "    logdir=Path(\"gestures\"),\n",
    "    train_steps=len(train),\n",
    "    valid_steps=len(valid),\n",
    "    reporttypes=[ReportTypes.TOML, ReportTypes.TENSORBOARD, ReportTypes.MLFLOW],\n",
    "    scheduler_kwargs={\"factor\": 0.5, \"patience\": 5},\n",
    "    earlystop_kwargs = {\n",
    "        \"save\": True, # save every best model, and restore the best one\n",
    "        \"verbose\": True,\n",
    "        \"patience\": 5, # number of epochs with no improvement after which training will be stopped\n",
    "        \"delta\": 0.0, # minimum change to be considered an improvement\n",
    "    }\n",
    ")\n",
    "settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    input_size: int\n",
    "    hidden_size: int\n",
    "    num_layers: int\n",
    "    output_size: int\n",
    "    dropout: float = 0.0\n",
    "\n",
    "class GRUmodel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.rnn = nn.GRU(\n",
    "            input_size=config.input_size,\n",
    "            hidden_size=config.hidden_size,\n",
    "            dropout=config.dropout,\n",
    "            batch_first=True,\n",
    "            num_layers=config.num_layers,\n",
    "        )\n",
    "        self.linear = nn.Linear(config.hidden_size, config.output_size)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x, _ = self.rnn(x)\n",
    "        last_step = x[:, -1, :]\n",
    "        yhat = self.linear(last_step)\n",
    "        return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/04 22:48:18 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2025/10/04 22:48:18 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "c:\\Master Applied Data Science\\Year 2\\Semester 3 (Deep Learning & Model Deployment)\\Portfolio-Marcello-Wienhoven\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-04 22:48:18.387\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to gestures\\20251004-224818\u001b[0m\n",
      "\u001b[32m2025-10-04 22:48:19.543\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 44.66it/s]\n",
      "\u001b[32m2025-10-04 22:48:21.658\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 2.5166 test 2.2426 metric ['0.2219']\u001b[0m\n",
      "\u001b[32m2025-10-04 22:48:21.658\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (2.2426 --> 2.2426).Saving gestures\\20251004-224818\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 36.41it/s]\n",
      "\u001b[32m2025-10-04 22:48:24.140\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 1.9809 test 1.7016 metric ['0.3969']\u001b[0m\n",
      "\u001b[32m2025-10-04 22:48:24.140\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (2.2426 --> 1.7016).Saving gestures\\20251004-224818\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 31.89it/s]\n",
      "\u001b[32m2025-10-04 22:48:26.929\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 1.3466 test 1.1019 metric ['0.5984']\u001b[0m\n",
      "\u001b[32m2025-10-04 22:48:26.930\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (1.7016 --> 1.1019).Saving gestures\\20251004-224818\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 37.04it/s]\n",
      "\u001b[32m2025-10-04 22:48:29.306\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.7962 test 0.5958 metric ['0.8266']\u001b[0m\n",
      "\u001b[32m2025-10-04 22:48:29.307\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (1.1019 --> 0.5958).Saving gestures\\20251004-224818\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 42.26it/s]\n",
      "\u001b[32m2025-10-04 22:48:31.427\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.4279 test 0.3106 metric ['0.9141']\u001b[0m\n",
      "\u001b[32m2025-10-04 22:48:31.427\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.5958 --> 0.3106).Saving gestures\\20251004-224818\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 43.82it/s]\n",
      "\u001b[32m2025-10-04 22:48:33.485\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 5 train 0.1842 test 0.1867 metric ['0.9547']\u001b[0m\n",
      "\u001b[32m2025-10-04 22:48:33.485\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.3106 --> 0.1867).Saving gestures\\20251004-224818\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 40.24it/s]\n",
      "\u001b[32m2025-10-04 22:48:35.695\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 6 train 0.1696 test 0.6121 metric ['0.8297']\u001b[0m\n",
      "\u001b[32m2025-10-04 22:48:35.696\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.1867, current loss 0.6121.Counter 1/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 43.34it/s]\n",
      "\u001b[32m2025-10-04 22:48:37.766\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 7 train 0.3541 test 0.1732 metric ['0.9625']\u001b[0m\n",
      "\u001b[32m2025-10-04 22:48:37.767\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.1867 --> 0.1732).Saving gestures\\20251004-224818\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 42.01it/s]\n",
      "\u001b[32m2025-10-04 22:48:39.893\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 8 train 0.0687 test 0.0833 metric ['0.9875']\u001b[0m\n",
      "\u001b[32m2025-10-04 22:48:39.895\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.1732 --> 0.0833).Saving gestures\\20251004-224818\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 44.28it/s]\n",
      "\u001b[32m2025-10-04 22:48:41.946\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 9 train 0.0416 test 0.0889 metric ['0.9844']\u001b[0m\n",
      "\u001b[32m2025-10-04 22:48:41.946\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0833, current loss 0.0889.Counter 1/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 45.07it/s]\n",
      "\u001b[32m2025-10-04 22:48:43.943\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 10 train 0.0278 test 0.0757 metric ['0.9859']\u001b[0m\n",
      "\u001b[32m2025-10-04 22:48:43.945\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.0833 --> 0.0757).Saving gestures\\20251004-224818\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 45.08it/s]\n",
      "\u001b[32m2025-10-04 22:48:45.945\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 11 train 0.0232 test 0.1189 metric ['0.9719']\u001b[0m\n",
      "\u001b[32m2025-10-04 22:48:45.946\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0757, current loss 0.1189.Counter 1/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 43.77it/s]\n",
      "\u001b[32m2025-10-04 22:48:48.009\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 12 train 0.0258 test 0.0625 metric ['0.9906']\u001b[0m\n",
      "\u001b[32m2025-10-04 22:48:48.010\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.0757 --> 0.0625).Saving gestures\\20251004-224818\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 42.80it/s]\n",
      "\u001b[32m2025-10-04 22:48:50.106\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 13 train 0.0117 test 0.0629 metric ['0.9891']\u001b[0m\n",
      "\u001b[32m2025-10-04 22:48:50.107\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0625, current loss 0.0629.Counter 1/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 43.48it/s]\n",
      "\u001b[32m2025-10-04 22:48:52.165\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 14 train 0.0102 test 0.0626 metric ['0.9859']\u001b[0m\n",
      "\u001b[32m2025-10-04 22:48:52.166\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0625, current loss 0.0626.Counter 2/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 43.61it/s]\n",
      "\u001b[32m2025-10-04 22:48:54.366\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 15 train 0.0081 test 0.0651 metric ['0.9844']\u001b[0m\n",
      "\u001b[32m2025-10-04 22:48:54.366\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0625, current loss 0.0651.Counter 3/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 16/16 [00:34<00:00,  2.17s/it]\n",
      "c:\\Master Applied Data Science\\Year 2\\Semester 3 (Deep Learning & Model Deployment)\\Portfolio-Marcello-Wienhoven\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\n",
      "\u001b[32m2025-10-04 22:48:54.402\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to gestures\\20251004-224854\u001b[0m\n",
      "\u001b[32m2025-10-04 22:48:54.403\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 43.62it/s]\n",
      "\u001b[32m2025-10-04 22:48:56.455\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 2.5499 test 2.3305 metric ['0.1953']\u001b[0m\n",
      "\u001b[32m2025-10-04 22:48:56.456\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (2.3305 --> 2.3305).Saving gestures\\20251004-224854\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 43.57it/s]\n",
      "\u001b[32m2025-10-04 22:48:58.503\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 1.9897 test 1.7936 metric ['0.3703']\u001b[0m\n",
      "\u001b[32m2025-10-04 22:48:58.505\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (2.3305 --> 1.7936).Saving gestures\\20251004-224854\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 40.14it/s]\n",
      "\u001b[32m2025-10-04 22:49:00.733\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 1.3335 test 1.0822 metric ['0.5859']\u001b[0m\n",
      "\u001b[32m2025-10-04 22:49:00.734\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (1.7936 --> 1.0822).Saving gestures\\20251004-224854\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 43.35it/s]\n",
      "\u001b[32m2025-10-04 22:49:02.826\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.7977 test 0.6695 metric ['0.7766']\u001b[0m\n",
      "\u001b[32m2025-10-04 22:49:02.827\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (1.0822 --> 0.6695).Saving gestures\\20251004-224854\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 42.43it/s]\n",
      "\u001b[32m2025-10-04 22:49:04.948\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.4392 test 0.4495 metric ['0.8688']\u001b[0m\n",
      "\u001b[32m2025-10-04 22:49:04.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.6695 --> 0.4495).Saving gestures\\20251004-224854\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 43.50it/s]\n",
      "\u001b[32m2025-10-04 22:49:07.014\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 5 train 0.2119 test 0.1751 metric ['0.9609']\u001b[0m\n",
      "\u001b[32m2025-10-04 22:49:07.015\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.4495 --> 0.1751).Saving gestures\\20251004-224854\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 42.07it/s]\n",
      "\u001b[32m2025-10-04 22:49:09.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 6 train 0.0940 test 0.1506 metric ['0.9500']\u001b[0m\n",
      "\u001b[32m2025-10-04 22:49:09.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.1751 --> 0.1506).Saving gestures\\20251004-224854\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 45.22it/s]\n",
      "\u001b[32m2025-10-04 22:49:11.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 7 train 0.0832 test 0.1198 metric ['0.9703']\u001b[0m\n",
      "\u001b[32m2025-10-04 22:49:11.121\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.1506 --> 0.1198).Saving gestures\\20251004-224854\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 43.24it/s]\n",
      "\u001b[32m2025-10-04 22:49:13.244\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 8 train 0.1475 test 0.2061 metric ['0.9437']\u001b[0m\n",
      "\u001b[32m2025-10-04 22:49:13.244\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.1198, current loss 0.2061.Counter 1/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 31.33it/s]\n",
      "\u001b[32m2025-10-04 22:49:16.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 9 train 0.1415 test 0.1026 metric ['0.9766']\u001b[0m\n",
      "\u001b[32m2025-10-04 22:49:16.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.1198 --> 0.1026).Saving gestures\\20251004-224854\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 30.39it/s]\n",
      "\u001b[32m2025-10-04 22:49:19.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 10 train 0.0505 test 0.1172 metric ['0.9750']\u001b[0m\n",
      "\u001b[32m2025-10-04 22:49:19.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.1026, current loss 0.1172.Counter 1/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 31.75it/s]\n",
      "\u001b[32m2025-10-04 22:49:21.813\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 11 train 0.0346 test 0.0905 metric ['0.9812']\u001b[0m\n",
      "\u001b[32m2025-10-04 22:49:21.814\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.1026 --> 0.0905).Saving gestures\\20251004-224854\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 32.17it/s]\n",
      "\u001b[32m2025-10-04 22:49:24.584\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 12 train 0.0191 test 0.0748 metric ['0.9766']\u001b[0m\n",
      "\u001b[32m2025-10-04 22:49:24.585\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.0905 --> 0.0748).Saving gestures\\20251004-224854\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 32.04it/s]\n",
      "\u001b[32m2025-10-04 22:49:27.365\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 13 train 0.0156 test 0.0674 metric ['0.9875']\u001b[0m\n",
      "\u001b[32m2025-10-04 22:49:27.365\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.0748 --> 0.0674).Saving gestures\\20251004-224854\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 31.87it/s]\n",
      "\u001b[32m2025-10-04 22:49:30.161\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 14 train 0.0102 test 0.0453 metric ['0.9891']\u001b[0m\n",
      "\u001b[32m2025-10-04 22:49:30.162\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.0674 --> 0.0453).Saving gestures\\20251004-224854\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 32.02it/s]\n",
      "\u001b[32m2025-10-04 22:49:32.946\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 15 train 0.0085 test 0.0595 metric ['0.9844']\u001b[0m\n",
      "\u001b[32m2025-10-04 22:49:32.947\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0453, current loss 0.0595.Counter 1/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 16/16 [00:38<00:00,  2.41s/it]\n",
      "\u001b[32m2025-10-04 22:49:32.983\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to gestures\\20251004-224932\u001b[0m\n",
      "\u001b[32m2025-10-04 22:49:32.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 31.10it/s]\n",
      "\u001b[32m2025-10-04 22:49:35.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 2.4903 test 2.1510 metric ['0.2094']\u001b[0m\n",
      "\u001b[32m2025-10-04 22:49:35.835\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (2.1510 --> 2.1510).Saving gestures\\20251004-224932\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 32.35it/s]\n",
      "\u001b[32m2025-10-04 22:49:38.588\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 1.9125 test 1.8049 metric ['0.3641']\u001b[0m\n",
      "\u001b[32m2025-10-04 22:49:38.588\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (2.1510 --> 1.8049).Saving gestures\\20251004-224932\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 32.05it/s]\n",
      "\u001b[32m2025-10-04 22:49:41.360\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 1.3847 test 1.1612 metric ['0.5891']\u001b[0m\n",
      "\u001b[32m2025-10-04 22:49:41.360\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (1.8049 --> 1.1612).Saving gestures\\20251004-224932\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 32.83it/s]\n",
      "\u001b[32m2025-10-04 22:49:44.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.8261 test 0.6826 metric ['0.7719']\u001b[0m\n",
      "\u001b[32m2025-10-04 22:49:44.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (1.1612 --> 0.6826).Saving gestures\\20251004-224932\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 32.42it/s]\n",
      "\u001b[32m2025-10-04 22:49:46.831\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.4904 test 0.5001 metric ['0.8359']\u001b[0m\n",
      "\u001b[32m2025-10-04 22:49:46.831\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.6826 --> 0.5001).Saving gestures\\20251004-224932\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 31.82it/s]\n",
      "\u001b[32m2025-10-04 22:49:49.621\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 5 train 0.2585 test 0.2583 metric ['0.9391']\u001b[0m\n",
      "\u001b[32m2025-10-04 22:49:49.622\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.5001 --> 0.2583).Saving gestures\\20251004-224932\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 31.94it/s]\n",
      "\u001b[32m2025-10-04 22:49:52.408\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 6 train 0.1348 test 0.1852 metric ['0.9484']\u001b[0m\n",
      "\u001b[32m2025-10-04 22:49:52.409\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.2583 --> 0.1852).Saving gestures\\20251004-224932\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 32.41it/s]\n",
      "\u001b[32m2025-10-04 22:49:55.151\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 7 train 0.1003 test 0.1497 metric ['0.9672']\u001b[0m\n",
      "\u001b[32m2025-10-04 22:49:55.152\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.1852 --> 0.1497).Saving gestures\\20251004-224932\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 29.79it/s]\n",
      "\u001b[32m2025-10-04 22:49:58.164\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 8 train 0.0694 test 0.1230 metric ['0.9656']\u001b[0m\n",
      "\u001b[32m2025-10-04 22:49:58.164\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.1497 --> 0.1230).Saving gestures\\20251004-224932\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 28.85it/s]\n",
      "\u001b[32m2025-10-04 22:50:01.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 9 train 0.0492 test 0.0968 metric ['0.9797']\u001b[0m\n",
      "\u001b[32m2025-10-04 22:50:01.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.1230 --> 0.0968).Saving gestures\\20251004-224932\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 28.79it/s]\n",
      "\u001b[32m2025-10-04 22:50:04.366\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 10 train 0.0308 test 0.1088 metric ['0.9797']\u001b[0m\n",
      "\u001b[32m2025-10-04 22:50:04.366\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0968, current loss 0.1088.Counter 1/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 27.58it/s]\n",
      "\u001b[32m2025-10-04 22:50:07.570\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 11 train 0.0251 test 0.1663 metric ['0.9609']\u001b[0m\n",
      "\u001b[32m2025-10-04 22:50:07.571\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0968, current loss 0.1663.Counter 2/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 29.28it/s]\n",
      "\u001b[32m2025-10-04 22:50:10.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 12 train 0.0692 test 0.1064 metric ['0.9781']\u001b[0m\n",
      "\u001b[32m2025-10-04 22:50:10.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0968, current loss 0.1064.Counter 3/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 29.97it/s]\n",
      "\u001b[32m2025-10-04 22:50:13.589\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 13 train 0.0228 test 0.0842 metric ['0.9875']\u001b[0m\n",
      "\u001b[32m2025-10-04 22:50:13.589\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.0968 --> 0.0842).Saving gestures\\20251004-224932\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 28.82it/s]\n",
      "\u001b[32m2025-10-04 22:50:16.680\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 14 train 0.0148 test 0.0922 metric ['0.9781']\u001b[0m\n",
      "\u001b[32m2025-10-04 22:50:16.680\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0842, current loss 0.0922.Counter 1/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 28.43it/s]\n",
      "\u001b[32m2025-10-04 22:50:19.797\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 15 train 0.0066 test 0.0744 metric ['0.9875']\u001b[0m\n",
      "\u001b[32m2025-10-04 22:50:19.798\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mValidation loss (0.0842 --> 0.0744).Saving gestures\\20251004-224932\\checkpoint.pt ...\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 16/16 [00:46<00:00,  2.93s/it]\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from datetime import datetime\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"gestures\")\n",
    "modeldir = Path(\"gestures\").resolve()\n",
    "if not modeldir.exists():\n",
    "    modeldir.mkdir(parents=True)\n",
    "    \n",
    "n_repeats = 3\n",
    "\n",
    "for repeat in range(n_repeats):\n",
    "    print(f\"Repeat {repeat+1}/{n_repeats}\")\n",
    "    \n",
    "    with mlflow.start_run():\n",
    "        # Set MLflow tags to record metadata about the model and developer\n",
    "        mlflow.set_tag(\"model\", f\"{repeat}_GRU_16epochs_0.5drop_256hidsize\")\n",
    "        mlflow.set_tag(\"dev\", \"Marcello\")\n",
    "        # Log hyperparameters to MLflow\n",
    "\n",
    "        mlflow.log_param(\"epochs\", settings.epochs)\n",
    "\n",
    "        mlflow.log_param(\"learning_rate\", settings.optimizer_kwargs.get(\"lr\", None))\n",
    "        \n",
    "        config = ModelConfig(\n",
    "            input_size=3,\n",
    "            hidden_size=256,\n",
    "            num_layers=1,\n",
    "            output_size=20,\n",
    "            dropout=0.5,\n",
    "        )\n",
    "\n",
    "        model = GRUmodel(\n",
    "            config=config,\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            settings=settings,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optim.Adam,\n",
    "            traindataloader=trainstreamer,\n",
    "            validdataloader=validstreamer,\n",
    "            scheduler=optim.lr_scheduler.ReduceLROnPlateau,\n",
    "            device=device,\n",
    "        )\n",
    "        trainer.loop()\n",
    "\n",
    "        if not settings.earlystop_kwargs[\"save\"]:\n",
    "            tag = datetime.now().strftime(\"%Y%m%d-%H%M-\")\n",
    "            modelpath = modeldir / (tag + \"model.pt\")\n",
    "            torch.save(model, modelpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open MLFlow\n",
    "\"\"\"\n",
    "```bash\n",
    "mlflow server \\\n",
    "    --backend-store-uri sqlite:///mlflow.db \\\n",
    "    --host 127.0.0.1 \\ \n",
    "    --port 5000 \\\n",
    "        \n",
    "mlflow server --backend-store-uri sqlite:///3-hypertuning-rnn/mlflow.db --host 127.0.0.1 --port 5000\n",
    "```\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "portfolio-example",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
